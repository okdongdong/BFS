{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dac3996a",
   "metadata": {},
   "source": [
    "### 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee04f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotVisibleException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "options.add_argument('headless')\n",
    "options.add_argument('lang=ko_KR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865622c2",
   "metadata": {},
   "source": [
    "### 검색을 위한 지하철 정보 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33d6c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "subway = pd.read_csv('./busansubway.csv', encoding='cp949')\n",
    "\n",
    "# null값 제거 및 원활한 검색을 위해 부산 name 붙여주기\n",
    "subway_lst = []\n",
    "for i in range(len(subway)):\n",
    "    if pd.isna(subway['역명'].iloc[i]) == True:\n",
    "        pass\n",
    "    else:\n",
    "        subway_lst.append(\"부산 \"+subway['역명'].iloc[i].split('(')[0] + \"역\")\n",
    "        \n",
    "\n",
    "categories = ['한식', '중식', '카페', '술집', '고기집', '횟집', '해산물', '밥집', '분식', '패스트푸드', '파스타', '뷔페', '국물요리', '면요리', '이탈리안', '프렌치', '아시안']\n",
    "# print(subway_lst)\n",
    "# print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb8de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_lst = []\n",
    "for subway in subway_lst:\n",
    "    url = 'https://www.diningcode.com/list.php?query={}'.format(subway)\n",
    "    \n",
    "    driver = webdriver.Chrome('./chromedriver')\n",
    "    driver.implicitly_wait(4)\n",
    "    driver.get(url)\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # 부산이 2만개넘는데 해당역이 없으면 2만개가 출력된다.\n",
    "    food_string = soup.body.select('#lbl_count')\n",
    "    food_string2 = food_string[0].text\n",
    "    cnt = int(re.sub(r'[^0-9]', '', food_string2))\n",
    "    \n",
    "    # 대략 넘으면 넘긴다.\n",
    "    if cnt > 10000:\n",
    "        continue\n",
    "    # 10~1000개 정도수준이면 카테고리별로 출력해서 뽑아낸다.\n",
    "    else:\n",
    "        for category in categories:\n",
    "            sub_url = 'https://www.diningcode.com/list.php?query={}%20{}'.format(subway, category)\n",
    "            url_lst.append(sub_url)\n",
    "            time.sleep(1)\n",
    "\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085936e2",
   "metadata": {},
   "source": [
    "### 가게 url 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d7bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_lst = []\n",
    "\n",
    "for url in url_lst:\n",
    "    driver = webdriver.Chrome('./chromedriver')\n",
    "    driver.implicitly_wait(2)\n",
    "    driver.get(url)\n",
    "    \n",
    "    count = 0\n",
    "    while count < 10:\n",
    "    #     print(count)\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "            # 스크롤 끝까지 내리기\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "            time.sleep(1)\n",
    "            # 스크롤 다운 후 스크롤 높이 다시 가져옴\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "        try:\n",
    "            driver.find_element_by_xpath('//*[@id=\"div_list_more\"]/span').click()\n",
    "            count += 1\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            print(\"빠진다.\", url)\n",
    "            break\n",
    "            \n",
    "    restaurants = driver.find_elements_by_css_selector('#div_list > [onmouseenter]')\n",
    "    for res in restaurants:\n",
    "        res_id = res.find_element_by_css_selector(\"a\").get_attribute('href')\n",
    "        store_lst.append(res_id)\n",
    "    \n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89a624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복링크 제거\n",
    "dupl_store = list(set(store_lst))\n",
    "df_store = pd.DataFrame({'url': dupl_store})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff139f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장\n",
    "df_store.to_csv(path_or_buf='store_url.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a3d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.read_csv('./store_url.csv', encoding='cp949', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c183735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['name', 'category', 'address', 'tel', 'time', 'menu', 'image']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "for url in store:\n",
    "    driver = webdriver.Chrome('./chromedriver')\n",
    "    driver.implicitly_wait(1) \n",
    "    driver.get(url)\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        name = soup.body.select('#div_profile > div.s-list.pic-grade > div.tit-point > p')[0].text\n",
    "    except:\n",
    "        name = ''\n",
    "    \n",
    "    category_lst = []\n",
    "    try:\n",
    "        for i in soup.body.select('#div_profile > div.s-list.pic-grade > div.btxt > a'):\n",
    "            category_lst.append(i.text)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        address = soup.body.select('#div_profile > div.s-list.basic-info > ul > li.locat')[0].text\n",
    "    except:\n",
    "        address = ''\n",
    "        \n",
    "    try:\n",
    "        tel = soup.body.select('#div_profile > div.s-list.basic-info > ul > li.tel')[0].text\n",
    "    except:\n",
    "        tel = ''\n",
    "    \n",
    "    try:\n",
    "        sub_day = []\n",
    "        for i in soup.body.select('#div_detail > div.busi-hours.short > ul > li'):\n",
    "            a = i.select('li > p.l-txt')[0].text\n",
    "            b = i.select('li > p.r-txt')[0].text.rstrip()\n",
    "            c = a + b\n",
    "            sub_day.append(c)\n",
    "        time_lst = '|'.join(sub_day)\n",
    "    except:\n",
    "        time_lst = \"\"\n",
    "        \n",
    "    menu = []\n",
    "    try:\n",
    "        for i in soup.body.select('#div_detail > div.menu-info.short > ul > li'):\n",
    "            menu.append((i.select('p')[0].text.split('\\n')[0], i.select('p')[1].text))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        image_url = soup.body.select('#div_profile > div.s-list.pic-grade > ul > li.bimg.btn-gallery-open > div > div > img')[0]['src']\n",
    "    except:\n",
    "        image_url = ''\n",
    "        \n",
    "        \n",
    "    df = df.append({\n",
    "        'name': name,\n",
    "        'category': category_lst,\n",
    "        'address' : address,\n",
    "        'tel': tel,\n",
    "        'time': time_lst,\n",
    "        'menu': menu,\n",
    "        'image': image_url\n",
    "    }, ignore_index=True)\n",
    "    time.sleep(0.5)\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff4d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장\n",
    "df.to_csv(path_or_buf='store_list.csv', encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
